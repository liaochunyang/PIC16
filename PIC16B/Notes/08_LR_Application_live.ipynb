{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression: Application\n",
    "\n",
    "In this notes, we will use linear regression model to predict insurance charge. Our main goal of this notes is addressing some practical issues we may face in real world application.\n",
    "\n",
    "Let's first read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/liaochunyang/PIC16/refs/heads/main/PIC16B/04_ML/insurance.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there are three numeric variables and three categorical variables. The last column `charges` is the label. Before we construct machine learning model, we should analyze our data. For example, we can check the distribution of numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use barplot to get some useful information. For example, the average chargers is much higher if the driver is a smoker. However, the average charges of subgroup male and female are similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides data visualization, you can also use pandas dataframe to get some quantitative results, for example, the mean and standard deviation of each subgroup (groupby). We will left this part for exercise.\n",
    "\n",
    "After data visualization, we should preprocess our data before we use them to train machine learning models. Let me write a function to change categorical columns to numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot and label are two common encoding techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next question is really interesting! Recall that we need to split our data to training dataset and test dataset because we want to create an unseen dataset for model evaluation. The natural question is \n",
    "\n",
    "    Do we do train_test_split before or after data pre-processing?\n",
    "\n",
    "My understanding is the following:\n",
    "\n",
    "- It depends on the processing you want to do. For example, one-hot encoding and label encoding should be done before train test split. \n",
    "\n",
    "However, some processing techniques should be done after train test split (even if I notice that some researchers do not do this). The goal of machine learning is to construct some models that can generalize well. The generalization property is measured by looking at the performance on unseen data. The role of test data is to measure the model performance, so we should make sure that test data are unseen data. It means that you cannot use test data to train the model. Moreover, you cannot leak any test data information. \n",
    "\n",
    "\n",
    "In the next example, we will do the minmax scaling for numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the results are different. In this situation, the order of train_test_split and data processing matters. In my opinion, **it is better to do train_test_split first** since we do not use test data information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
